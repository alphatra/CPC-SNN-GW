# üöÄ MEMORY-OPTIMIZED TRAINING CONFIGURATION - 50 EPOCHS
# Ultra-optimized for systems with limited memory (16GB RAM + T4 GPU)
# Target: >85% accuracy with minimal memory footprint

# üìä Experiment Configuration
experiment:
  name: "cpc_snn_gw_memory_optimized_50_epochs"
  version: "memory_safe_v1.0"
  description: "Memory-optimized 50-epoch training - all enhancements with minimal footprint"
  target_accuracy: 0.85
  scientific_validation: true

# üåä Ultra-Compact Data Configuration
data:
  # Memory-optimized LIGO parameters
  use_real_ligo_data: true
  sample_rate: 4096
  sequence_length: 128        # REDUCED: 256‚Üí128 for memory
  window_size: 128           # REDUCED: 256‚Üí128 for memory
  enhanced_overlap: 0.5      # REDUCED: 0.9‚Üí0.5 for memory
  num_samples: 800           # REDUCED: 2000‚Üí800 for memory
  data_augmentation: false   # DISABLED: for memory
  noise_scaling: false       # DISABLED: for memory
  
  # Minimal preprocessing
  min_snr: 8.0              # INCREASED: more selective
  preprocessing:
    whitening: true
    bandpass_low: 35.0
    bandpass_high: 350.0
    scaling_factor: 1e20

# üß† Memory-Optimized Model Architecture
model:
  # Compact CPC Encoder
  cpc:
    latent_dim: 64             # REDUCED: 128‚Üí64
    downsample_factor: 8       # INCREASED: 4‚Üí8 for memory
    context_length: 64         # REDUCED: 256‚Üí64
    prediction_steps: 4        # REDUCED: 8‚Üí4
    num_negatives: 4           # REDUCED: 8‚Üí4
    temperature: 0.07
    conv_channels: [32, 64]    # REDUCED: [64,128,256]‚Üí[32,64]
    
    # Minimal Temporal Transformer
    use_temporal_transformer: true
    transformer_num_heads: 2   # REDUCED: 4‚Üí2
    transformer_num_layers: 1  # REDUCED: 2‚Üí1
    multi_scale_kernels: [3, 5] # REDUCED: [3,5,7]‚Üí[3,5]
    temporal_attention_dropout: 0.2
    
  # Compact Spike Bridge
  spike_bridge:
    encoding_strategy: "phase_preserving"
    use_learnable_thresholds: true
    num_threshold_scales: 2    # REDUCED: 4‚Üí2
    threshold_adaptation_rate: 0.01
    use_phase_preserving_encoding: true
    edge_detection_thresholds: 2 # REDUCED: 4‚Üí2
    
  # Compact SNN Classifier  
  snn:
    hidden_sizes: [64, 32]     # REDUCED: [128,64]‚Üí[64,32]
    num_classes: 2
    snn_neurons_per_layer: 128 # REDUCED: 512‚Üí128
    snn_num_layers: 2          # REDUCED: 4‚Üí2
    
    # Optimized LIF parameters
    tau_mem: 50e-6
    tau_syn: 10e-6
    threshold: 1.0
    use_enhanced_lif: true
    use_refractory_period: true
    use_adaptation: true
    refractory_time_constant: 2e-3
    adaptation_time_constant: 20e-3
    
    # Simplified surrogate gradients
    surrogate_gradient_type: "ADAPTIVE_MULTI_SCALE"
    surrogate_gradient_beta: 2.0  # REDUCED: 4.0‚Üí2.0
    curriculum_learning: false    # DISABLED: for memory

# üéØ Memory-Safe Training Configuration
training:
  # Ultra-conservative parameters
  num_epochs: 50
  batch_size: 1              # MINIMAL: for memory safety
  learning_rate: 1e-3        # INCREASED: faster convergence
  weight_decay: 1e-4
  
  # Simple learning rate schedule
  learning_rate_schedule: "constant"  # SIMPLIFIED
  warmup_epochs: 0           # DISABLED: for simplicity
  
  # Minimal gradient optimization
  gradient_clipping: true
  max_gradient_norm: 0.5     # REDUCED: 1.0‚Üí0.5
  gradient_accumulation_steps: 8  # INCREASED: effective batch=8
  
  # Minimal regularization
  dropout_rate: 0.05         # REDUCED: 0.1‚Üí0.05
  use_mixed_precision: false # DISABLED: potential memory issues
  
  # Conservative early stopping
  early_stopping_patience: 15
  early_stopping_metric: "loss"
  early_stopping_mode: "min"

# üßÆ Simplified Mathematical Framework
mathematical_framework:
  # Basic InfoNCE
  use_temporal_infonce: true
  temporal_context_length: 64 # REDUCED: 256‚Üí64
  temporal_negative_samples: 4 # REDUCED: 8‚Üí4
  
  # Simplified temperature
  use_adaptive_temperature: false # DISABLED: for simplicity
  initial_temperature: 0.07
  
  # Minimal SNN capacity
  simulation_time_steps: 64   # REDUCED: 256‚Üí64
  simulation_dt: 0.5e-3       # INCREASED: less resolution
  
  # Disabled complex features
  use_pac_bayes_regularization: false # DISABLED: for memory
  gradient_stability_monitoring: false # DISABLED: for memory

# üöÄ Simplified Enhancements
enhancements:
  # Keep core enhancements, simplify others
  surrogate_adaptivity_factor: 1.5    # REDUCED: 2.0‚Üí1.5
  use_momentum_negatives: false       # DISABLED: for memory
  negative_momentum: 0.9              # REDUCED: 0.999‚Üí0.9
  hard_negative_ratio: 0.2            # REDUCED: 0.3‚Üí0.2
  curriculum_temperature: false       # DISABLED: for simplicity

# üñ•Ô∏è Ultra-Conservative Platform Config
platform:
  device: "cpu"              # FORCE CPU: avoid GPU memory issues
  precision: "float32"
  memory_fraction: 0.05      # ULTRA-CONSERVATIVE: 5%
  enable_jit: true
  cache_compilation: false   # DISABLED: save memory

# üíæ Minimal GPU Optimization
gpu_optimization:
  memory_fraction: 0.05      # ULTRA-CONSERVATIVE
  enable_jit: true
  cache_compilation: false   # DISABLED: save memory
  
  # Minimal warmup
  comprehensive_gpu_warmup: false # DISABLED: save time/memory
  warmup_stages: 0
  
  # Conservative XLA
  xla_python_client_preallocate: false
  xla_python_client_mem_fraction: 0.05

# üìä Minimal Monitoring
monitoring:
  # Basic W&B
  use_wandb: true
  wandb_project: "cpc_snn_gw_memory_optimized"
  wandb_run_name: "memory_safe_training"
  
  # Conservative logging
  log_every_n_steps: 50      # REDUCED frequency
  eval_every_n_epochs: 10    # REDUCED frequency
  save_every_n_epochs: 10    # REDUCED frequency
  
  # Minimal tracking
  track_gradient_norms: false # DISABLED: save memory
  track_spike_patterns: false # DISABLED: save memory
  track_attention_weights: false # DISABLED: save memory
  track_temperature_adaptation: false # DISABLED: save memory
  
  # Output directory
  output_dir: "outputs/memory_optimized_training"
  save_best_model: true
  save_final_model: true

# üéØ Realistic Performance Targets
targets:
  # Conservative accuracy targets
  target_train_accuracy: 0.90
  target_test_accuracy: 0.85
  target_roc_auc: 0.90
  
  # Performance targets
  target_inference_time: 0.2   # Relaxed: <200ms
  target_energy_efficiency: 0.01
  target_spike_rate: 0.02     # 2% average
  
  # Quality metrics
  no_model_collapse: true
  gradient_flow_healthy: true
  cpc_loss_working: true

# üìä Minimal Evaluation & Baselines
evaluation:
  metrics: ["accuracy", "roc_auc", "f1"]  # REDUCED set
  target_accuracy: 0.85
  confidence_intervals: false # DISABLED: save memory
  bootstrap_samples: 0        # DISABLED: save memory

baselines:
  pycbc_template_bank: false  # DISABLED: save memory
  matched_filtering: false    # DISABLED: save memory
  statistical_significance: false # DISABLED: save memory

validation:
  comprehensive_test_evaluation: true
  model_collapse_detection: true
  data_leakage_prevention: true
  confidence_intervals: false # DISABLED: save memory
  bootstrap_samples: 0        # DISABLED: save memory
  statistical_significance: false # DISABLED: save memory
  compare_with_pycbc: false   # DISABLED: save memory
  compare_with_matched_filtering: false # DISABLED: save memory

# üìù Basic Logging
logging:
  level: "INFO"
  use_wandb: true
  wandb_project: "cpc_snn_gw_memory_optimized"
  checkpoint_dir: "outputs/memory_optimized_training/checkpoints"
  save_every_n_epochs: 10
  log_every_n_steps: 50

# üö® Ultra-Safe Memory Management
safety:
  # Memory monitoring
  memory_monitoring: true
  swap_detection: true
  oom_prevention: true
  
  # Stability checks
  nan_detection: true
  inf_detection: true
  gradient_explosion_detection: true
  
  # Conservative model validation
  parameter_validation: false # DISABLED: save memory
  architecture_validation: false # DISABLED: save memory
  data_quality_validation: false # DISABLED: save memory 