name: Candidate Regression Gate

on:
  pull_request:
  push:
    branches:
      - main
      - master
      - phase2-robust-eval

jobs:
  baseline-regression-gate:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Resolve candidate report path
        id: resolve
        shell: bash
        run: |
          set -euo pipefail
          if [[ -f "configs/baselines/baseline_report_candidate.json" ]]; then
            echo "current_report=configs/baselines/baseline_report_candidate.json" >> "$GITHUB_OUTPUT"
          elif [[ -f "reports/baseline_report_candidate.json" ]]; then
            echo "current_report=reports/baseline_report_candidate.json" >> "$GITHUB_OUTPUT"
          else
            echo "[error] Missing candidate report."
            echo "Expected one of:"
            echo "  - configs/baselines/baseline_report_candidate.json"
            echo "  - reports/baseline_report_candidate.json"
            echo "Generate it first via scripts/generate_baseline_report_v0.py."
            exit 1
          fi

      - name: Resolve backend-specific lock (MPS-only)
        id: lock
        shell: bash
        run: |
          set -euo pipefail
          DEVICE="$(python - <<'PY'
import json, os
p=os.environ["CURRENT_REPORT"]
r=json.loads(open(p).read())
print(str(r.get("runtime",{}).get("device","")).lower())
PY
)"
          echo "runtime_device=$DEVICE" >> "$GITHUB_OUTPUT"
          if [[ "$DEVICE" != "mps" ]]; then
            echo "[error] candidate runtime.device=$DEVICE, expected mps for this workflow."
            exit 1
          fi
          LOCK_PATH="configs/baselines/baseline_lock_v1_full_mps.json"
          if [[ ! -f "$LOCK_PATH" ]]; then
            echo "[error] missing MPS lock: $LOCK_PATH"
            exit 1
          fi
          echo "lock_path=$LOCK_PATH" >> "$GITHUB_OUTPUT"
        env:
          CURRENT_REPORT: ${{ steps.resolve.outputs.current_report }}

      - name: Run regression gate
        env:
          PYTHONPATH: .
        run: |
          python scripts/check_baseline_regression.py \
            --current-report "${{ steps.resolve.outputs.current_report }}" \
            --lock "${{ steps.lock.outputs.lock_path }}" \
            --max-tpr-drop-abs 0.02 \
            --max-pauc-drop-abs 0.02 \
            --max-tpr-drop-abs-ood 0.005 \
            --max-pauc-drop-abs-ood 0.01 \
            --max-ece-increase-abs 0.01 \
            --max-brier-increase-abs 0.01 \
            --max-latency-increase-rel 0.30 \
            --require-nondecreasing-scopes ood_baseline \
            --nondecreasing-eps-tpr 0.003 \
            --nondecreasing-eps-pauc 0.002 \
            --enforce-same-device

      - name: Bootstrap compare (B vs C3 ensemble) if outputs exist
        env:
          PYTHONPATH: .
        run: |
          set -euo pipefail
          OUT_DIR="reports/ood_compare_b_vs_c3ens_drop43_add46"
          if [[ -f "$OUT_DIR/b_r1.txt" && -f "$OUT_DIR/c3ens_r1.txt" ]]; then
            python scripts/bootstrap_compare_b_vs_c3ens.py \
              --out-dir "$OUT_DIR" \
              --n-boot 20000 \
              --seed 123 \
              --min-delta 0.0 \
              --min-p-superiority 0.95
          else
            echo "[info] skipping bootstrap compare; missing repeat logs in $OUT_DIR"
          fi
